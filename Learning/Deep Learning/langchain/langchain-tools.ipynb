{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/generation/langchain/handbook/07-langchain-tools.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/generation/langchain/handbook/07-langchain-tools.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEfDPVJLEGIY"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain openai transformers"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TA0NIHMAM0Su"
      },
      "source": [
        "# Building Tools"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NdcnT-S-M2PB"
      },
      "source": [
        "Let's begin taking a look at how we can build custom tools. We'll start with some simple examples so we can understand the _flow_ of the tool building process."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4JjaNCuMFu_N"
      },
      "source": [
        "## Simple Calculator Tool"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2NRMiNEDEvkh"
      },
      "source": [
        "We will begin with a very simple *circumference* calculating tool that we will define like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1FplwAi9uTG"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import BaseTool\n",
        "from math import pi\n",
        "from typing import Union\n",
        "\n",
        "\n",
        "class CircumferenceTool(BaseTool):\n",
        "    name = \"Circumference calculator\"\n",
        "    description = \"use this tool when you need to calculate a circumference using the radius of a circle\"\n",
        "\n",
        "    def _run(self, radius: Union[int, float]):\n",
        "        return float(radius)*2.0*pi\n",
        "    \n",
        "    def _arun(self, radius: Union[int, float]):\n",
        "        raise NotImplementedError(\"This tool does not support async\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "trx8vU5nF4jU"
      },
      "source": [
        "When defining a tool like this using the `BaseTool` template we must define `name` and `description` attributes, alongside `_run` and `_arun` methods. When a tool us used the `_run` method is called by default. The `_arun` method is called when the tool is to be used *asyncronously*. We do not cover that in this walkthrough so for now we create it with a `NotImplementedError`."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5aTKHl50EzXf"
      },
      "source": [
        "We need to initialize the agent LLM and *conversational memory*. For the LLM we will use `gpt-3.5-turbo` from OpenAI, to use this you need an [OpenAI API key](https://platform.openai.com).\n",
        "\n",
        "_Note: Using the OpenAI API costs money, the examples below are not very large so the costs should not be significant._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JgkbOyaEFSK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "\n",
        "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY') or 'OPENAI_API_KEY'\n",
        "\n",
        "# initialize LLM (we use ChatOpenAI because we'll later define a `chat` agent)\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    temperature=0,\n",
        "    model_name='gpt-3.5-turbo'\n",
        ")\n",
        "# initialize conversational memory\n",
        "conversational_memory = ConversationBufferWindowMemory(\n",
        "    memory_key='chat_history',\n",
        "    k=5,\n",
        "    return_messages=True\n",
        ")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vv8yp25aAYIU"
      },
      "source": [
        "Now we initialize the agent itself. To use the circumference tool we defined above we must add it to a list that we then pass to the `tools` parameter within `initialize_agent`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FevHfYMaAYg6"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import initialize_agent\n",
        "\n",
        "tools = [CircumferenceTool()]\n",
        "\n",
        "# initialize agent with tools\n",
        "agent = initialize_agent(\n",
        "    agent='chat-conversational-react-description',\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=3,\n",
        "    early_stopping_method='generate',\n",
        "    memory=conversational_memory\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qhIw4yDjAznp"
      },
      "source": [
        "Now let's try and ask it to calculate the circumference of a circle:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHDCS0IUFhBd",
        "outputId": "828506de-2a17-4088-bb60-4df7c5dcd3ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"The circumference of a circle with a radius of 7.81mm is approximately 49.03mm.\"\n",
            "}\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'can you calculate the circumference of a circle that has a radius of 7.81mm',\n",
              " 'chat_history': [],\n",
              " 'output': 'The circumference of a circle with a radius of 7.81mm is approximately 49.03mm.'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent(\"can you calculate the circumference of a circle that has a radius of 7.81mm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-Xibg0DFPb8",
        "outputId": "d78c04a5-9cd6-421b-f343-1f658e076cf3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "49.071677249072565"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(7.81 * 2) * pi"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj4dD2lDGDuO"
      },
      "source": [
        "The answer is pretty close but not quite right. We can see in the outputs above that the model decided not to use the circumference calculator tool, that is because it is (falsely) confident in it's ability to answer the question.\n",
        "\n",
        "To fix this we need to tell the model in the prompt that it *cannot* do this. We do this like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7KenZBRF_-u",
        "outputId": "e1af774c-c875-44ab-85ba-de7cccc16a4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant is a large language model trained by OpenAI.\n",
            "\n",
            "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n"
          ]
        }
      ],
      "source": [
        "# existing prompt\n",
        "print(agent.agent.llm_chain.prompt.messages[0].prompt.template)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KQj-XpSCG1Bm"
      },
      "source": [
        "Let's modify the existing system message to emphasize that the LLM is *terrible at maths* (fourth line):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihE-icnWGjDH"
      },
      "outputs": [],
      "source": [
        "sys_msg = \"\"\"Assistant is a large language model trained by OpenAI.\n",
        "\n",
        "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
        "\n",
        "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
        "\n",
        "Unfortunately, Assistant is terrible at maths. When provided with math questions, no matter how simple, assistant always refers to it's trusty tools and absolutely does NOT try to answer math questions by itself\n",
        "\n",
        "Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
        "\"\"\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VQwuQwn1HSBw"
      },
      "source": [
        "And update our prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYLRHpG_HRT-"
      },
      "outputs": [],
      "source": [
        "new_prompt = agent.agent.create_prompt(\n",
        "    system_message=sys_msg,\n",
        "    tools=tools\n",
        ")\n",
        "\n",
        "agent.agent.llm_chain.prompt = new_prompt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kmSJnf6AK3nN"
      },
      "source": [
        "Now we try again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrr25SN9Hi6l",
        "outputId": "2e4f363d-d3e7-47c4-bfcb-a7172a3436ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "    \"action\": \"Circumference calculator\",\n",
            "    \"action_input\": \"7.81\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m49.071677249072565\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"The circumference of a circle with a radius of 7.81mm is approximately 49.07mm.\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'can you calculate the circumference of a circle that has a radius of 7.81mm',\n",
              " 'chat_history': [HumanMessage(content='can you calculate the circumference of a circle that has a radius of 7.81mm', additional_kwargs={}),\n",
              "  AIMessage(content='The circumference of a circle with a radius of 7.81mm is approximately 49.03mm.', additional_kwargs={})],\n",
              " 'output': 'The circumference of a circle with a radius of 7.81mm is approximately 49.07mm.'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent(\"can you calculate the circumference of a circle that has a radius of 7.81mm\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dX9q3BSVFnEV"
      },
      "source": [
        "Now the model uses the **Circumference calculator** and consequently gets the correct answer."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XnuPuwp7GW2O"
      },
      "source": [
        "## Tools with Multiple Parameters"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gnypVGoKHgDl"
      },
      "source": [
        "Tools can also handle multiple parameters, let's try and build a Pythagoras tool. The tool helps us calculate the hypotenuse of a triangle given a combination of side lengths and/or angles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqe0T2lHK7jI"
      },
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "from math import sqrt, cos, sin\n",
        "\n",
        "desc = (\n",
        "    \"use this tool when you need to calculate the length of an hypotenuse \"\n",
        "    \"given one or two sides of a triangle and/or an angle (in degrees). \"\n",
        "    \"To use the tool you must provide at least two of the following parameters \"\n",
        "    \"['adjacent_side', 'opposite_side', 'angle'].\"\n",
        ")\n",
        "\n",
        "class PythagorasTool(BaseTool):\n",
        "    name = \"Hypotenuse calculator\"\n",
        "    description = desc\n",
        "\n",
        "    def _run(\n",
        "        self,\n",
        "        adjacent_side: Optional[Union[int, float]] = None,\n",
        "        opposite_side: Optional[Union[int, float]] = None,\n",
        "        angle: Optional[Union[int, float]] = None\n",
        "    ):\n",
        "        # check for the values we have been given\n",
        "        if adjacent_side and opposite_side:\n",
        "            return sqrt(float(adjacent_side)**2 + float(opposite_side)**2)\n",
        "        elif adjacent_side and angle:\n",
        "            return adjacent_side / cos(float(angle))\n",
        "        elif opposite_side and angle:\n",
        "            return opposite_side / sin(float(angle))\n",
        "        else:\n",
        "            return \"Could not calculate the hypotenuse of the triangle. Need two or more of `adjacent_side`, `opposite_side`, or `angle`.\"\n",
        "    \n",
        "    def _arun(self, query: str):\n",
        "        raise NotImplementedError(\"This tool does not support async\")\n",
        "\n",
        "tools = [PythagorasTool()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCux2HDjJqNo"
      },
      "outputs": [],
      "source": [
        "new_prompt = agent.agent.create_prompt(\n",
        "    system_message=sys_msg,\n",
        "    tools=tools\n",
        ")\n",
        "\n",
        "agent.agent.llm_chain.prompt = new_prompt\n",
        "# update the agent tools\n",
        "agent.tools = tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2vy_44BK5fu",
        "outputId": "410213f9-a002-426b-96bb-4cf19afaaf8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3m{\n",
            "    \"action\": \"Hypotenuse calculator\",\n",
            "    \"action_input\": {\n",
            "        \"adjacent_side\": 34,\n",
            "        \"opposite_side\": 51\n",
            "    }\n",
            "}\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m61.29437168288782\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"The length of the hypotenuse is approximately 61.29cm.\"\n",
            "}\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'If I have a triangle with two sides of length 51cm and 34cm, what is the length of the hypotenuse?',\n",
              " 'chat_history': [HumanMessage(content='can you calculate the circumference of a circle that has a radius of 7.81mm', additional_kwargs={}),\n",
              "  AIMessage(content='The circumference of a circle with a radius of 7.81mm is approximately 49.03mm.', additional_kwargs={}),\n",
              "  HumanMessage(content='can you calculate the circumference of a circle that has a radius of 7.81mm', additional_kwargs={}),\n",
              "  AIMessage(content='The circumference of a circle with a radius of 7.81mm is approximately 49.07mm.', additional_kwargs={})],\n",
              " 'output': 'The length of the hypotenuse is approximately 61.29cm.'}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent(\"If I have a triangle with two sides of length 51cm and 34cm, what is the length of the hypotenuse?\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DJVV8PoDyj3F"
      },
      "source": [
        "## More Advanced Tool Usage"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "u26tI4dVjKRr"
      },
      "source": [
        "We just built two quick examples of very simple tools. In most scenarios we'd probably like to do something a little more complex â€” so let's build something more interesting.\n",
        "\n",
        "We will take inspiration from the [Hugging GPT paper](https://arxiv.org/pdf/2303.17580.pdf), where to others describe what is essentially a ensemble of open source models trained for different tasks, that are controlled by a LLM. In our example we will take one of the existing open source models that is able to caption images called `Salesforce/blip-image-captioning-large`.\n",
        "\n",
        "We initialize the model like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QjQYXhMset9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "hf_model = \"Salesforce/blip-image-captioning-large\"\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "processor = BlipProcessor.from_pretrained(hf_model)\n",
        "model = BlipForConditionalGeneration.from_pretrained(hf_model).to(device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nv6KibM-5PNy"
      },
      "source": [
        "To generate a caption for an image we need to first download it and open it as a PIL image object. We do this like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "ahzJlmXP3b6P",
        "outputId": "486906f1-2861-4f4a-fdf7-9bcc860fbbe4"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "img_url = 'https://images.unsplash.com/photo-1616128417859-3a984dd35f02?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2372&q=80' \n",
        "image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
        "image"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3OfgvCNO5xRE"
      },
      "source": [
        "Now we process the image using the model `processor` and generate the caption using `model.generate`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg_d0rrY5b_q",
        "outputId": "1a3598fd-2911-486c-a51b-06efcb17ca6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "there is a monkey that is sitting in a tree\n"
          ]
        }
      ],
      "source": [
        "# unconditional image captioning\n",
        "inputs = processor(image, return_tensors=\"pt\").to(device)\n",
        "\n",
        "out = model.generate(**inputs, max_new_tokens=20)\n",
        "print(processor.decode(out[0], skip_special_tokens=True))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GIfuC-u66Ip6"
      },
      "source": [
        "Perfect, we can use this process as the logic for our new image captioning tool. Let's first define the tool class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KoNqkyy6Tie"
      },
      "outputs": [],
      "source": [
        "desc = (\n",
        "    \"use this tool when given the URL of an image that you'd like to be \"\n",
        "    \"described. It will return a simple caption describing the image.\"\n",
        ")\n",
        "\n",
        "class ImageCaptionTool(BaseTool):\n",
        "    name = \"Image captioner\"\n",
        "    description = desc\n",
        "\n",
        "    def _run(self, url: str):\n",
        "        # download the image and convert to PIL object\n",
        "        image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
        "        # preprocess the image\n",
        "        inputs = processor(image, return_tensors=\"pt\").to(device)\n",
        "        # generate the caption\n",
        "        out = model.generate(**inputs, max_new_tokens=20)\n",
        "        # get the caption\n",
        "        caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "        return caption\n",
        "    \n",
        "    def _arun(self, query: str):\n",
        "        raise NotImplementedError(\"This tool does not support async\")\n",
        "\n",
        "tools = [ImageCaptionTool()]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rMLPQWmo7XMs"
      },
      "source": [
        "Let's reinitialize our agent prompt and set the `tools` attribute to reflect the new tool list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04Wy4tNv9H7j"
      },
      "outputs": [],
      "source": [
        "sys_msg = \"\"\"Assistant is a large language model trained by OpenAI.\n",
        "\n",
        "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
        "\n",
        "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
        "\n",
        "Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
        "\"\"\"\n",
        "\n",
        "new_prompt = agent.agent.create_prompt(\n",
        "    system_message=sys_msg,\n",
        "    tools=tools\n",
        ")\n",
        "\n",
        "agent.agent.llm_chain.prompt = new_prompt\n",
        "# update the agent tools\n",
        "agent.tools = tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iavwx689WN_",
        "outputId": "e007cfac-42db-4c8a-9cb5-21c80ed5d310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m{\n",
            "    \"action\": \"Image captioner\",\n",
            "    \"action_input\": \"https://images.unsplash.com/photo-1616128417859-3a984dd35f02?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2372&q=80\"\n",
            "}\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mthere is a monkey that is sitting in a tree\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"There is a monkey that is sitting in a tree.\"\n",
            "}\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'What does this image show?\\nhttps://images.unsplash.com/photo-1616128417859-3a984dd35f02?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2372&q=80',\n",
              " 'chat_history': [HumanMessage(content='can you calculate the circumference of a circle that has a radius of 7.81mm', additional_kwargs={}),\n",
              "  AIMessage(content='The circumference of a circle with a radius of 7.81mm is approximately 49.03mm.', additional_kwargs={}),\n",
              "  HumanMessage(content='can you calculate the circumference of a circle that has a radius of 7.81mm', additional_kwargs={}),\n",
              "  AIMessage(content='The circumference of a circle with a radius of 7.81mm is approximately 49.07mm.', additional_kwargs={}),\n",
              "  HumanMessage(content='If I have a triangle with two sides of length 51cm and 34cm, what is the length of the hypotenuse?', additional_kwargs={}),\n",
              "  AIMessage(content='The length of the hypotenuse is approximately 61.29cm.', additional_kwargs={})],\n",
              " 'output': 'There is a monkey that is sitting in a tree.'}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent(f\"What does this image show?\\n{img_url}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "M04OX3bC9iz5"
      },
      "source": [
        "Let's try some more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "S2Xep5eYBV-B",
        "outputId": "d01219ce-9c60-4f55-8e8d-ec68f42581e1"
      },
      "outputs": [],
      "source": [
        "img_url = \"https://images.unsplash.com/photo-1680382948929-2d092cd01263?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2365&q=80\"\n",
        "image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_0oWtahHA5D",
        "outputId": "e623ba75-4bee-4bc2-da4b-2f619e461b49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "    \"action\": \"Image captioner\",\n",
            "    \"action_input\": \"https://images.unsplash.com/photo-1680382948929-2d092cd01263?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2365&q=80\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mthere is a lizard that is sitting on a tree branch in the water\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"There is a lizard that is sitting on a tree branch in the water.\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'what is in this image?\\nhttps://images.unsplash.com/photo-1680382948929-2d092cd01263?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2365&q=80',\n",
              " 'chat_history': [HumanMessage(content='can you calculate the circumference of a circle that has a radius of 7.81mm', additional_kwargs={}),\n",
              "  AIMessage(content='The circumference of a circle with a radius of 7.81mm is approximately 49.03mm.', additional_kwargs={}),\n",
              "  HumanMessage(content='can you calculate the circumference of a circle that has a radius of 7.81mm', additional_kwargs={}),\n",
              "  AIMessage(content='The circumference of a circle with a radius of 7.81mm is approximately 49.07mm.', additional_kwargs={}),\n",
              "  HumanMessage(content='If I have a triangle with two sides of length 51cm and 34cm, what is the length of the hypotenuse?', additional_kwargs={}),\n",
              "  AIMessage(content='The length of the hypotenuse is approximately 61.29cm.', additional_kwargs={}),\n",
              "  HumanMessage(content='What does this image show?\\nhttps://images.unsplash.com/photo-1616128417859-3a984dd35f02?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2372&q=80', additional_kwargs={}),\n",
              "  AIMessage(content='There is a monkey that is sitting in a tree.', additional_kwargs={}),\n",
              "  HumanMessage(content='what is in this image?\\nhttps://images.unsplash.com/photo-1502680390469-be75c86b636f?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2370&q=80', additional_kwargs={}),\n",
              "  AIMessage(content='The image shows a surfer riding a wave in the ocean on a clear day.', additional_kwargs={})],\n",
              " 'output': 'There is a lizard that is sitting on a tree branch in the water.'}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent(f\"what is in this image?\\n{img_url}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "j6NA83vZIP02"
      },
      "source": [
        "Looks pretty good. Naturally, we can build much more complex tools, or simply add new tools to our agents."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
